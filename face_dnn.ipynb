{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Karthick47v2/mock-buddy/blob/main/haar_cascade_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iMQRAoqvx-s0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 16:22:54.048866: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dedsec/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-07-07 16:22:54.048888: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 96\n",
    "edge_offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 44100\n",
    "frames_per_buffer = 1024\n",
    "no_of_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 16:26:44.788704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-07 16:26:44.789177: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dedsec/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-07-07 16:26:44.789264: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dedsec/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-07-07 16:26:44.789317: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dedsec/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-07-07 16:26:44.789368: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dedsec/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-07-07 16:26:44.789430: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dedsec/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-07-07 16:26:44.789481: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dedsec/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-07-07 16:26:44.789548: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dedsec/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-07-07 16:26:44.789595: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/dedsec/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-07-07 16:26:44.789602: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-07-07 16:26:44.826152: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('conv_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def draw_landmark(frame, rgb_frame):\n",
    "  landmarks = model.predict(np.expand_dims(frame.reshape(img_size,img_size,1),0))\n",
    "\n",
    "  for x_coord, y_coord in zip(landmarks[0, 0:136:2], landmarks[0, 1:136:2]):\n",
    "    rgb_frame = cv2.circle(rgb_frame, tuple((int(x_coord),int(y_coord))), radius=1, color=(255,255,255), thickness=1)\n",
    "\n",
    "  y_axis = landmarks[0, 54:62:2].mean()\n",
    "\n",
    "  interactivity = abs(y_axis - (img_size / 2))\n",
    "\n",
    "  abs_l = np.abs(landmarks[0, 0:16:2] - y_axis).mean()\n",
    "  abs_r = np.abs(landmarks[0, 18:34:2] - y_axis).mean()\n",
    "\n",
    "  ln = abs(abs_l - abs_r)\n",
    "\n",
    "  threshold = 15 + 2\n",
    "  if ln > threshold:\n",
    "    rgb_frame = cv2.rectangle(rgb_frame, (0,0), (10,10), color=(0,0,255), thickness=-1)\n",
    "  return rgb_frame, interactivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_func():\n",
    "    #\n",
    "    audio = pyaudio.PyAudio()\n",
    "    stream = audio.open(format=pyaudio.paInt16, channels=no_of_channels,\n",
    "                        rate=sample_rate, frames_per_buffer=frames_per_buffer, input=True)\n",
    "\n",
    "    audio_frames = []\n",
    "    i  = 0\n",
    "    while i < 1000:\n",
    "        print(i)\n",
    "        i += 1\n",
    "        audio_frames.append(stream.read(frames_per_buffer))\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    sound_file = wave.open(\"rec.wav\", \"wb\")\n",
    "    sound_file.setnchannels(no_of_channels)\n",
    "    sound_file.setsampwidth(audio.get_sample_size(pyaudio.paInt16))\n",
    "    sound_file.setframerate(sample_rate)\n",
    "    sound_file.writeframes(b''.join(audio_frames))\n",
    "    sound_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_w_pad(img, req_size):\n",
    "  original_shape = (img.shape[1], img.shape[0])\n",
    "\n",
    "  ratio = float(max(req_size))/max(original_shape)\n",
    "  new_size = [int(x*ratio) for x in original_shape]\n",
    "\n",
    "  img = cv2.resize(img, tuple(new_size))\n",
    "  delta_w, delta_h = req_size[0] - new_size[0], req_size[1] - new_size[1]\n",
    "  top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "  left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "\n",
    "  img = cv2.copyMakeBorder(img, top, bottom, left, right,\n",
    "                           cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "  return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "D8PjD9fx1Y4A"
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) /io/opencv/modules/dnn/src/caffe/caffe_io.cpp:1126: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"dnn/deploy.prototxt\" in function 'ReadProtoFromTextFile'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m/home/dedsec/Documents/github/mock-buddy/face_dnn.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dedsec/Documents/github/mock-buddy/face_dnn.ipynb#ch0000009?line=0'>1</a>\u001b[0m intrav \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dedsec/Documents/github/mock-buddy/face_dnn.ipynb#ch0000009?line=1'>2</a>\u001b[0m face_dnn \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mdnn\u001b[39m.\u001b[39;49mreadNetFromCaffe(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dedsec/Documents/github/mock-buddy/face_dnn.ipynb#ch0000009?line=2'>3</a>\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mdnn/deploy.prototxt\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mdnn/res10_300x300_ssd_iter_140000.caffemodel\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dedsec/Documents/github/mock-buddy/face_dnn.ipynb#ch0000009?line=4'>5</a>\u001b[0m cap \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mVideoCapture(\u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dedsec/Documents/github/mock-buddy/face_dnn.ipynb#ch0000009?line=6'>7</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /io/opencv/modules/dnn/src/caffe/caffe_io.cpp:1126: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"dnn/deploy.prototxt\" in function 'ReadProtoFromTextFile'\n"
     ]
    }
   ],
   "source": [
    "intrav = []\n",
    "face_dnn = cv2.dnn.readNetFromCaffe(\n",
    "    'dnn/deploy.prototxt', 'dnn/res10_300x300_ssd_iter_140000.caffemodel')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "  ret, frame = cap.read()\n",
    "\n",
    "  (height, width) = frame.shape[:2]\n",
    "  blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300,300)),1.0, (300,300), (104.0, 177.0, 123.0))\n",
    "  face_dnn.setInput(blob)\n",
    "\n",
    "  detections = face_dnn.forward()\n",
    "\n",
    "  for i in range(0, detections.shape[2]):\n",
    "\n",
    "    if detections[0, 0, i, 2] > 0.8:\n",
    "\n",
    "      bbox = detections[0,0,i,3:7] * np.array([width, height, width, height])\n",
    "      (start_x, start_y, end_x, end_y) = bbox.astype('int')\n",
    "\n",
    "      frame = np.array(frame[start_y: end_y, start_x: end_x])\n",
    "      g_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "      g_frame = resize_w_pad(\n",
    "          g_frame, (img_size, img_size)).astype(np.uint8)\n",
    "\n",
    "      rgb_frame = resize_w_pad(\n",
    "          frame, (img_size, img_size)).astype(np.uint8)\n",
    "\n",
    "      frame, intractiv = draw_landmark(g_frame, rgb_frame)\n",
    "\n",
    "      intrav.append(intractiv)\n",
    "      break\n",
    "\n",
    "  # cv2.namedWindow('frame', cv2.WINDOW_NORMAL)\n",
    "  # cv2.resizeWindow('frame', 300, 300)\n",
    "  cv2.imshow('frame', frame)\n",
    "\n",
    "  # return if q pressed\n",
    "  if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    break\n",
    "\n",
    "# release webcamq\n",
    "cap.release()\n",
    "\n",
    "# close window\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.503059579180433\n"
     ]
    }
   ],
   "source": [
    "print(sum(intrav)/len(intrav))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "\n",
    "#     audio_cpu = mp.Process(target=audio_func)\n",
    "#     video_cpu = mp.Process(target=video_func)\n",
    "#     audio_cpu.start()\n",
    "#     video_cpu.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Qt: Session management error: Could not open network socket\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/dedsec/Documents/github/mock-buddy/haar_cascade_classifier.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dedsec/Documents/github/mock-buddy/haar_cascade_classifier.ipynb#ch0000011?line=0'>1</a>\u001b[0m \u001b[39m# audio_func()\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dedsec/Documents/github/mock-buddy/haar_cascade_classifier.ipynb#ch0000011?line=1'>2</a>\u001b[0m video_func()\n",
      "\u001b[1;32m/home/dedsec/Documents/github/mock-buddy/haar_cascade_classifier.ipynb Cell 8'\u001b[0m in \u001b[0;36mvideo_func\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dedsec/Documents/github/mock-buddy/haar_cascade_classifier.ipynb#ch0000008?line=47'>48</a>\u001b[0m   person_not_facing \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dedsec/Documents/github/mock-buddy/haar_cascade_classifier.ipynb#ch0000008?line=48'>49</a>\u001b[0m   \u001b[39m##########################\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/dedsec/Documents/github/mock-buddy/haar_cascade_classifier.ipynb#ch0000008?line=50'>51</a>\u001b[0m cv2\u001b[39m.\u001b[39;49mimshow(\u001b[39m'\u001b[39;49m\u001b[39mframe\u001b[39;49m\u001b[39m'\u001b[39;49m, frame)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dedsec/Documents/github/mock-buddy/haar_cascade_classifier.ipynb#ch0000008?line=52'>53</a>\u001b[0m \u001b[39m# return if q pressed\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/dedsec/Documents/github/mock-buddy/haar_cascade_classifier.ipynb#ch0000008?line=53'>54</a>\u001b[0m \u001b[39mif\u001b[39;00m cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m1\u001b[39m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# audio_func()\n",
    "# video_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPeiIJoDogLGabc3CeI0u3X",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "haar-cascade-classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
